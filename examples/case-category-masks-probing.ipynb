{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "case category masks probing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IQHe9eu0BuC",
        "outputId": "f98f8ded-47c2-4efa-8e90-df8808089bb6"
      },
      "source": [
        "%%writefile xlmr_downloader.sh\n",
        "\n",
        "mkdir -p xlmr/de\n",
        "cd xlmr/de\n",
        "\n",
        "for fn in config.json  eval_results.txt  pytorch_model.bin  sentencepiece.bpe.model  special_tokens_map.json  test_predictions.txt  test_results.txt  tokenizer_config.json  training_args.bin ; do\n",
        "  wget --continue --quiet --show-progress files.deeppavlov.ai/morph-probing/models/xlmr/de/${fn};\n",
        "done;\n",
        "\n",
        "cd ../..\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing xlmr_downloader.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kt9BuHj_VeCY",
        "outputId": "d2fae76b-c2ca-4ab0-854d-3243b6e7af01"
      },
      "source": [
        "!bash xlmr_downloader.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "config.json         100%[===================>]   1.14K  --.-KB/s    in 0s      \n",
            "eval_results.txt    100%[===================>]     183  --.-KB/s    in 0s      \n",
            "pytorch_model.bin   100%[===================>]   1.04G  8.28MB/s    in 2m 32s  \n",
            "sentencepiece.bpe.m 100%[===================>]   4.83M  3.47MB/s    in 1.4s    \n",
            "special_tokens_map. 100%[===================>]     150  --.-KB/s    in 0s      \n",
            "test_predictions.tx 100%[===================>]   4.08M  2.90MB/s    in 1.4s    \n",
            "test_results.txt    100%[===================>]     170  --.-KB/s    in 0s      \n",
            "tokenizer_config.js 100%[===================>]      25  --.-KB/s    in 0s      \n",
            "training_args.bin   100%[===================>]   1.21K  --.-KB/s    in 0s      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdIYoVj9Qu6v",
        "outputId": "b535b471-9844-47b1-d910-86a85f232cbd"
      },
      "source": [
        "%%writefile minilm_downloader.sh\n",
        "\n",
        "mkdir -p minilm/de\n",
        "cd minilm/de\n",
        "\n",
        "for fn in config.json  eval_results.txt  pytorch_model.bin  sentencepiece.bpe.model  special_tokens_map.json  test_predictions.txt  test_results.txt  tokenizer_config.json  training_args.bin ; do\n",
        "  wget --continue --quiet --show-progress files.deeppavlov.ai/morph-probing/models/minilm/de/${fn};\n",
        "done;\n",
        "\n",
        "cd ../..\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing minilm_downloader.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnN0oRj9R4OK",
        "outputId": "901f8d90-73ed-48e4-c8af-3f116a24c801"
      },
      "source": [
        "!bash minilm_downloader.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "config.json         100%[===================>]   1.07K  --.-KB/s    in 0s      \n",
            "eval_results.txt    100%[===================>]     179  --.-KB/s    in 0s      \n",
            "pytorch_model.bin   100%[===================>] 448.89M  9.30MB/s    in 62s     \n",
            "sentencepiece.bpe.m 100%[===================>]   4.83M  3.34MB/s    in 1.4s    \n",
            "special_tokens_map. 100%[===================>]     150  --.-KB/s    in 0s      \n",
            "test_predictions.tx 100%[===================>]   4.08M  3.18MB/s    in 1.3s    \n",
            "test_results.txt    100%[===================>]     171  --.-KB/s    in 0s      \n",
            "tokenizer_config.js 100%[===================>]      25  --.-KB/s    in 0s      \n",
            "training_args.bin   100%[===================>]   1.22K  --.-KB/s    in 0s      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETMPjt0l4Udy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "390533ba-fa5e-4964-bd69-45836239d7d5"
      },
      "source": [
        "%%writefile experiment.sh\n",
        "rm -rf transformers*\n",
        "git clone https://github.com/morphology-probing/transformers-morph-probing-tools.git\n",
        "cd transformers-morph-probing-tools/\n",
        "rm -rf transformers*\n",
        "python -m pip install -r requirements.txt\n",
        "\n",
        "\n",
        "\n",
        "sed -i \"s|INFO|DEBUG|g\" probe.py\n",
        "sed -i \"s|DO_MASKING=False|DO_MASKING=True|\" constants.py\n",
        "\n",
        "\n",
        "model=minilm\n",
        "lang=de\n",
        "category=case\n",
        "experiment_file=${lang}_cat_${category}\n",
        "wget -c \"https://files.deeppavlov.ai/morph-probing/datasets/${category}/${experiment_file}.tsv\"\n",
        "\n",
        "model_ft_path=\"/content/${model}/$lang\"\n",
        "python3 probe.py infer_and_probe ${experiment_file}.tsv --model_is_random=False \\\n",
        "                                                    --model_is_finetuned=False \\\n",
        "                                                    --model_architecture=${model} \\\n",
        "                                                    --model_finetuned_path ${model_ft_path}\n",
        "\n",
        "NEWEST_DIR_NAME=$(ls -td inference_results/* | head -n 1)\n",
        "ARCHIVE_NAME=oleg_err_$(basename $NEWEST_DIR_NAME | perl -pe \"s|.*?([\\d-]+).*|\\1|g\").tar.gz\n",
        "FILES_TO_ZIP=$(find $NEWEST_DIR_NAME -name \"*json\" -o -name \"*log\")\n",
        "tar -zcf $ARCHIVE_NAME $FILES_TO_ZIP\n",
        "# ~/.local/bin/telegram-send --config channel.conf --file $ARCHIVE_NAME \\\n",
        "#                                                 --caption \"$(basename $NEWEST_DIR_NAME)\"\n",
        "# rm $ARCHIVE_NAME\n",
        "find inference_results/ -name db.sqlite -type f -delete\n",
        "\n",
        "\n",
        "model=minilm\n",
        "lang=de\n",
        "category=case\n",
        "experiment_file=${lang}_cat_${category}\n",
        "wget -c \"https://files.deeppavlov.ai/morph-probing/datasets/${category}/${experiment_file}.tsv\"\n",
        "\n",
        "model_ft_path=\"/content/${model}/$lang\"\n",
        "python3 probe.py infer_and_probe ${experiment_file}.tsv --model_is_random=False \\\n",
        "                                                    --model_is_finetuned=True \\\n",
        "                                                    --model_architecture=${model} \\\n",
        "                                                    --model_finetuned_path ${model_ft_path}\n",
        "\n",
        "NEWEST_DIR_NAME=$(ls -td inference_results/* | head -n 1)\n",
        "ARCHIVE_NAME=oleg_err_$(basename $NEWEST_DIR_NAME | perl -pe \"s|.*?([\\d-]+).*|\\1|g\").tar.gz\n",
        "FILES_TO_ZIP=$(find $NEWEST_DIR_NAME -name \"*json\" -o -name \"*log\")\n",
        "tar -zcf $ARCHIVE_NAME $FILES_TO_ZIP\n",
        "# ~/.local/bin/telegram-send --config channel.conf --file $ARCHIVE_NAME \\\n",
        "#                                                 --caption \"$(basename $NEWEST_DIR_NAME)\"\n",
        "# rm $ARCHIVE_NAME\n",
        "find inference_results/ -name db.sqlite -type f -delete\n",
        "\n",
        "\n",
        "model=xlmr\n",
        "lang=de\n",
        "category=case\n",
        "experiment_file=${lang}_cat_${category}\n",
        "wget -c \"https://files.deeppavlov.ai/morph-probing/datasets/${category}/${experiment_file}.tsv\"\n",
        "\n",
        "model_ft_path=\"/content/${model}/$lang\"\n",
        "python3 probe.py infer_and_probe ${experiment_file}.tsv --model_is_random=False \\\n",
        "                                                    --model_is_finetuned=False \\\n",
        "                                                    --model_architecture=${model} \\\n",
        "                                                    --model_finetuned_path ${model_ft_path}\n",
        "\n",
        "NEWEST_DIR_NAME=$(ls -td inference_results/* | head -n 1)\n",
        "ARCHIVE_NAME=oleg_err_$(basename $NEWEST_DIR_NAME | perl -pe \"s|.*?([\\d-]+).*|\\1|g\").tar.gz\n",
        "FILES_TO_ZIP=$(find $NEWEST_DIR_NAME -name \"*json\" -o -name \"*log\")\n",
        "tar -zcf $ARCHIVE_NAME $FILES_TO_ZIP\n",
        "# ~/.local/bin/telegram-send --config channel.conf --file $ARCHIVE_NAME \\\n",
        "#                                                 --caption \"$(basename $NEWEST_DIR_NAME)\"\n",
        "# rm $ARCHIVE_NAME\n",
        "find inference_results/ -name db.sqlite -type f -delete\n",
        "\n",
        "\n",
        "model=xlmr\n",
        "lang=de\n",
        "category=case\n",
        "experiment_file=${lang}_cat_${category}\n",
        "wget -c \"https://files.deeppavlov.ai/morph-probing/datasets/${category}/${experiment_file}.tsv\"\n",
        "\n",
        "model_ft_path=\"/content/${model}/$lang\"\n",
        "python3 probe.py infer_and_probe ${experiment_file}.tsv --model_is_random=True \\\n",
        "                                                    --model_is_finetuned=False \\\n",
        "                                                    --model_architecture=${model} \\\n",
        "                                                    --model_finetuned_path ${model_ft_path}\n",
        "\n",
        "NEWEST_DIR_NAME=$(ls -td inference_results/* | head -n 1)\n",
        "ARCHIVE_NAME=oleg_err_$(basename $NEWEST_DIR_NAME | perl -pe \"s|.*?([\\d-]+).*|\\1|g\").tar.gz\n",
        "FILES_TO_ZIP=$(find $NEWEST_DIR_NAME -name \"*json\" -o -name \"*log\")\n",
        "tar -zcf $ARCHIVE_NAME $FILES_TO_ZIP\n",
        "# ~/.local/bin/telegram-send --config channel.conf --file $ARCHIVE_NAME \\\n",
        "#                                                 --caption \"$(basename $NEWEST_DIR_NAME)\"\n",
        "# rm $ARCHIVE_NAME\n",
        "find inference_results/ -name db.sqlite -type f -delete\n",
        "\n",
        "\n",
        "model=xlmr\n",
        "lang=de\n",
        "category=case\n",
        "experiment_file=${lang}_cat_${category}\n",
        "wget -c \"https://files.deeppavlov.ai/morph-probing/datasets/${category}/${experiment_file}.tsv\"\n",
        "\n",
        "model_ft_path=\"/content/${model}/$lang\"\n",
        "python3 probe.py infer_and_probe ${experiment_file}.tsv --model_is_random=False \\\n",
        "                                                    --model_is_finetuned=True \\\n",
        "                                                    --model_architecture=${model} \\\n",
        "                                                    --model_finetuned_path ${model_ft_path}\n",
        "\n",
        "NEWEST_DIR_NAME=$(ls -td inference_results/* | head -n 1)\n",
        "ARCHIVE_NAME=oleg_err_$(basename $NEWEST_DIR_NAME | perl -pe \"s|.*?([\\d-]+).*|\\1|g\").tar.gz\n",
        "FILES_TO_ZIP=$(find $NEWEST_DIR_NAME -name \"*json\" -o -name \"*log\")\n",
        "tar -zcf $ARCHIVE_NAME $FILES_TO_ZIP\n",
        "# ~/.local/bin/telegram-send --config channel.conf --file $ARCHIVE_NAME \\\n",
        "#                                                 --caption \"$(basename $NEWEST_DIR_NAME)\"\n",
        "# rm $ARCHIVE_NAME\n",
        "find inference_results/ -name db.sqlite -type f -delete\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting experiment.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCWpDG4M4oSU"
      },
      "source": [
        "!bash ./experiment.sh"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
